ğŸ§  ClusterizaÃ§Ã£o de Vinhos com PCA e K-Means
ğŸ¯ Objetivo

Este projeto tem como objetivo agrupar diferentes tipos de vinhos com base em suas caracterÃ­sticas quÃ­micas.
Utiliza-se o PCA (Principal Component Analysis) para reduzir a dimensionalidade dos dados e o K-Means para identificar agrupamentos (clusters) de vinhos semelhantes.

ğŸ“Š Dataset

O dataset utilizado Ã© o Wine Dataset, disponÃ­vel no Scikit-learn.
Ele contÃ©m 178 amostras de vinhos provenientes de 3 produtores diferentes, descritas por 13 variÃ¡veis quÃ­micas, como teor alcoÃ³lico, magnÃ©sio, flavonÃ³ides, entre outros.

âš™ï¸ Tecnologias e Bibliotecas

Python 3.x

Pandas

NumPy

Scikit-learn

Matplotlib

Seaborn

ğŸ§© Etapas do Projeto
1. Carregamento e PadronizaÃ§Ã£o dos Dados

Os dados sÃ£o carregados via load_wine() e normalizados com StandardScaler para garantir que todas as variÃ¡veis tenham a mesma escala â€” essencial para o PCA.

2. ReduÃ§Ã£o de Dimensionalidade com PCA

AplicaÃ§Ã£o do PCA para reduzir as 13 dimensÃµes originais para 2 componentes principais, facilitando a visualizaÃ§Ã£o dos dados em um plano 2D.
O PCA tambÃ©m indica a variÃ¢ncia explicada, ou seja, quanta informaÃ§Ã£o dos dados originais foi mantida apÃ³s a reduÃ§Ã£o.

3. Agrupamento com K-Means

O algoritmo K-Means Ã© aplicado sobre as duas componentes principais.
Define-se k = 3, pois sabemos que existem 3 tipos de vinho no dataset.
O resultado Ã© uma atribuiÃ§Ã£o de cada amostra a um cluster.

4. VisualizaÃ§Ã£o dos Resultados

Dois grÃ¡ficos principais sÃ£o gerados:

Clusters Encontrados pelo K-Means: mostra os agrupamentos descobertos automaticamente.

Classes Reais dos Vinhos: mostra as classes originais, servindo como base para comparaÃ§Ã£o.

Os centrÃ³ides dos clusters sÃ£o marcados com â€œXâ€ vermelhos.

ğŸ“ˆ Resultados e InterpretaÃ§Ã£o

O PCA geralmente explica mais de 55% da variÃ¢ncia total dos dados com apenas dois componentes.

O K-Means consegue separar bem os trÃªs grupos, mostrando que os vinhos possuem diferenÃ§as quÃ­micas consistentes.

A comparaÃ§Ã£o entre os grÃ¡ficos evidencia uma correspondÃªncia visual forte entre clusters e classes reais.

ğŸ§® CÃ³digo Simplificado
from sklearn.datasets import load_wine
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

wine_data = load_wine()
X = StandardScaler().fit_transform(wine_data.data)
y_true = wine_data.target

pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X)

kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
labels = kmeans.fit_predict(X_pca)

df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
df['Cluster'] = labels
df['Classe'] = y_true

plt.figure(figsize=(8,6))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=df, palette='viridis', s=100, alpha=0.8)
plt.title('ClusterizaÃ§Ã£o de Vinhos com PCA e K-Means')
plt.show()

print(f"VariÃ¢ncia explicada: {sum(pca.explained_variance_ratio_)*100:.2f}%")

ğŸš€ Como Executar no Google Colab

Crie um novo notebook no Google Colab
.

Copie e cole o cÃ³digo acima.

Execute todas as cÃ©lulas.

Visualize os grÃ¡ficos de clusterizaÃ§Ã£o e a variÃ¢ncia explicada.

ğŸ“š ConclusÃ£o

A combinaÃ§Ã£o de PCA e K-Means Ã© uma abordagem poderosa para explorar e visualizar dados de alta dimensionalidade.
Mesmo sem rÃ³tulos, Ã© possÃ­vel identificar padrÃµes naturais entre os vinhos, demonstrando a eficÃ¡cia da clusterizaÃ§Ã£o nÃ£o supervisionada.

ğŸ§¾ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT.
Sinta-se livre para usar, estudar e modificar o cÃ³digo.
